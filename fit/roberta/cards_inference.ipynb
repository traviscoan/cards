{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claims prediction with the RoBERTa classifier used in the Coan et al. (2021) article 'Computer-assisted detection and classification of misinformation about climate change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required packages\n",
    "\n",
    "# Dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# Regular expressions\n",
    "import re\n",
    "\n",
    "# Unidecoder\n",
    "import unicodedata\n",
    "\n",
    "# Timestamp / time measurment\n",
    "import time\n",
    "\n",
    "# Simpletransformers classifier\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "# Softmax function for predicted probabiliy calculation\n",
    "from scipy.special import softmax\n",
    "\n",
    "# PyTorch: enable GPU access\n",
    "import torch\n",
    "\n",
    "# If you want to select a specific GPU, set it here:\n",
    "# gpu = 0\n",
    "# torch.cuda.set_device(gpu) \n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use GPU {}:'.format(torch.cuda.current_device()), torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define required functions\n",
    "\n",
    "# Define text pre-processing functions\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "def remove_non_ascii(text):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "def strip_underscores(text):\n",
    "    return re.sub(r'_+', ' ', text)\n",
    "def remove_multiple_spaces(text):\n",
    "    return re.sub(r'\\s{2,}', ' ', text)\n",
    "\n",
    "# Merge text pre-processing functions\n",
    "def denoise_text(text):\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_non_ascii(text)\n",
    "    text = strip_underscores(text)\n",
    "    text = remove_multiple_spaces(text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text data\n",
    "data = pd.read_csv('analysis/extracted_paras.csv')\n",
    "print('{} paragraphs were loaded. Here are the first few rows of the data:'.format(len(data)))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the text\n",
    "data['text_denoised'] = data['text'].astype(str).apply(denoise_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict text labels (claims) with the pre-trained RoBERTa classifier used in the Coan et al. (2021) article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define the model \n",
    "architecture = 'roberta'\n",
    "model_name = 'CARDS_RoBERTa_Classifier'\n",
    "\n",
    "# Load the classifier\n",
    "model = ClassificationModel(architecture, model_name)\n",
    "\n",
    "# Predict the labels\n",
    "predictions, raw_outputs = model.predict(list(data.text_denoised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join predictions to the data\n",
    "data['RoBERTa_pred_label'] = predictions\n",
    "data['RoBERTa_pred_probabilities'] = [softmax(element[0]) for element in raw_outputs]\n",
    "\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
